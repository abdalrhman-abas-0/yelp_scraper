{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f3cafa",
   "metadata": {},
   "source": [
    "## Yelp Data Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5cfd8c",
   "metadata": {},
   "source": [
    "> ### Inputs Cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97249448",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_subject = \"accountants\"\n",
    "search_location = 'San Francisco, CA'# make a check that search makes the \n",
    "pages_to_scrape = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d1094",
   "metadata": {},
   "source": [
    "> ### Dependecies Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d8ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://www.yelp.com/search?find_desc=accountants&find_loc=San+Francisco%2C+CA\"\n",
    "from httpx_html import HTMLSession\n",
    "import time\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "from fake_useragent import UserAgent\n",
    "import os, glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbdd3d0",
   "metadata": {},
   "source": [
    "> ### Main Scraper Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e82c0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_df = True\n",
    "result_list =[]\n",
    "next = False\n",
    "site = url\n",
    "breaker = False\n",
    "previous_page = url\n",
    "results_scraped = 0\n",
    "save_index = 0###\n",
    "I = 0###\n",
    "date_time = str( f'{datetime.datetime.now()}')[:f'{datetime.datetime.now()}'.index('.')].replace(':','.')###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f9a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 pages available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;10;144;146m███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 6/6 [00:34<00:00,  5.80s/page]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary is done, 120 results Scraped successfully !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "ua = UserAgent()\n",
    "header = {'User-Agent': ua.random}\n",
    "\n",
    "\"\"\" scraping the internet\"\"\"      \n",
    "\"\"\" scraping the internet\"\"\"      \n",
    "session = HTMLSession()\n",
    "r = session.get(url)\n",
    "response = r.html\n",
    "\n",
    "results_available = int(response.find('div[class*=\"text-align--center\"] > span')[0].text.split(\" \")[-1]) # returns the number of resluts available for a given search\n",
    "print(f'{results_available} pages available.')\n",
    "\n",
    "try:\n",
    "    pages_to_scrape =list(range(pages_to_scrape+1))[I:]\n",
    "except:\n",
    "    pages_to_scrape = pages_to_scrape[I:]\n",
    "    \n",
    "if len(pages_to_scrape) > results_available:\n",
    "   pages_to_scrape = pages_to_scrape[:results_available -1]\n",
    "   \n",
    " \n",
    "for Page in tqdm(pages_to_scrape ,unit= \"page\", ncols = 160, colour= '#0A9092'):\n",
    "    \n",
    "    if next == True:\n",
    "        ua = UserAgent()\n",
    "        header = {\n",
    "                'User-Agent': ua,\n",
    "                'Origin': 'https://www.yellowpages.com',\n",
    "                'Referer':f'{previous_page}',\n",
    "                }\n",
    "        while True:\n",
    "            try:\n",
    "                \n",
    "                try:\n",
    "                    breaker = open(f'breaker.txt','r')\n",
    "                    breaker = True\n",
    "                    I = save_index\n",
    "                    break\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                session = HTMLSession()\n",
    "                r = session.get(site)\n",
    "                response = r.html\n",
    "                break\n",
    "            except:\n",
    "                # ua = UserAgent().random\n",
    "                sleep(5)  \n",
    "    if breaker == True:\n",
    "        break\n",
    "    \n",
    "    non_sponsored = response.xpath('//h3/span/a')\n",
    "        \n",
    "    if len(non_sponsored)>= 10:\n",
    "        non_sponsored = non_sponsored[-10:]\n",
    "    \n",
    "    for B in non_sponsored:# iterates through the results Milber Insurane\n",
    "        name = B.text\n",
    "        profile = url[:20] + list(B.links)[0]\n",
    "        # handling redirecting url \n",
    "        if \"&request_id\" in profile: \n",
    "            tru_url = profile[profile.index('url=https%')+len('url=https%'):profile.index('&request_id')]\n",
    "            divider_mark = tru_url[tru_url.index('com')+len('com'):tru_url.index('biz')]\n",
    "            profile = 'https://'+tru_url[tru_url.index('www'):].replace(divider_mark, '/')\n",
    "        \n",
    "        result = {\"Business Name\": name, \"Profile\": profile}\n",
    "        result_list.append(result)\n",
    "        \n",
    "        for key, value in result.items():\n",
    "            if value == '':\n",
    "                result[key] = \"Not Listed\"\n",
    "            \n",
    "        result_list.append(result)\n",
    "    \n",
    "\n",
    "    results_scraped += len(result_list)\n",
    "    save_index += 1\n",
    "    \n",
    "    m_df = pd.DataFrame(result_list)\n",
    "    m_df.to_csv(f\"yelp  {search_subject} in {search_location} {save_index} primary.csv\", index= False)\n",
    "    \n",
    "    result_list = []\n",
    "\n",
    "    try:\n",
    "        file = open(f'tracker {search_subject} in {search_location} at {date_time}.txt','a') \n",
    "    except:\n",
    "        file = open(f'tracker {search_subject} in {search_location} at {date_time}.txt','w')         \n",
    "    file.write('\\n')\n",
    "    file.write (f\"yelp  {search_subject} in {search_location} {save_index} primary.csv\") \n",
    "    file.write('\\n')\n",
    "    file.write(F'{site}')   \n",
    "    file.close() \n",
    "           \n",
    "    try:\n",
    "        previous_page = site\n",
    "        next_page = response.find('div[class*=\"pagination-links\"] > div')[-1]\n",
    "        site = list(next_page.links)[0]\n",
    "        next = True   \n",
    "    except:\n",
    "        print(\"scrapping is interrupted >>LAST PAGE ERROR<< !!\")\n",
    "        break\n",
    "    sleep(0.3)\n",
    "    \n",
    "print(f\"Primary is done, {results_scraped + len(result_list)} results Scraped successfully !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953759fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f'tracker {search_subject} in {search_location} at {date_time}.txt','r')\n",
    "for line in file:\n",
    "    \n",
    "    if f'{search_location} 1 primary' in line:\n",
    "        m_df0 = pd.read_csv(str(line).strip('\\n')) \n",
    "        continue \n",
    "     \n",
    "    if 'https://' not in line and 'primary' in line: #and ' 0 primary' not in line\n",
    "        m_df = pd.concat([m_df0, pd.read_csv(str(line).strip('\\n'))], axis=0, ignore_index= True)    \n",
    "        m_df0 = m_df\n",
    "        \n",
    "file.close()\n",
    "main_df = m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e8b143c-edf2-4cbc-a461-983cc5bb4418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Business Name  120 non-null    object\n",
      " 1   Profile        120 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1da60b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Name</th>\n",
       "      <th>Profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>JP Accountancy</td>\n",
       "      <td>https://www.yelp.com/biz/jp-accountancy-san-fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Mauricio Midence Tax Preparation &amp; Financial S...</td>\n",
       "      <td>https://www.yelp.com/biz/mauricio-midence-tax-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Mauricio Midence Tax Preparation &amp; Financial S...</td>\n",
       "      <td>https://www.yelp.com/biz/mauricio-midence-tax-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Kugelman Law Tax &amp; Cryptocurrency Attorneys</td>\n",
       "      <td>https://www.yelp.com/biz/kugelman-law-tax-and-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Kugelman Law Tax &amp; Cryptocurrency Attorneys</td>\n",
       "      <td>https://www.yelp.com/biz/kugelman-law-tax-and-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Business Name  \\\n",
       "115                                     JP Accountancy   \n",
       "116  Mauricio Midence Tax Preparation & Financial S...   \n",
       "117  Mauricio Midence Tax Preparation & Financial S...   \n",
       "118        Kugelman Law Tax & Cryptocurrency Attorneys   \n",
       "119        Kugelman Law Tax & Cryptocurrency Attorneys   \n",
       "\n",
       "                                               Profile  \n",
       "115  https://www.yelp.com/biz/jp-accountancy-san-fr...  \n",
       "116  https://www.yelp.com/biz/mauricio-midence-tax-...  \n",
       "117  https://www.yelp.com/biz/mauricio-midence-tax-...  \n",
       "118  https://www.yelp.com/biz/kugelman-law-tax-and-...  \n",
       "119  https://www.yelp.com/biz/kugelman-law-tax-and-...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed8b97ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv(f\"Yelp Main {search_subject} in {search_location}.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e08bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    if 'Main' in file or 'Secondary' in file :\n",
    "        continue\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1c08e",
   "metadata": {},
   "source": [
    "> ### Secondary Scraper Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_df = pd.read_csv('Yellow Pages Main New Car Dealers in NewYork.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ab542ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" separating the main list and the scrapped page variable to make prevent data loss when relaunching the scraper in \n",
    "    case of connection interruption\n",
    "\"\"\"\n",
    "contacts = []\n",
    "I = 0  # power interruption index saved in the .txt file\n",
    "profile_no = 0 # connection interruption index\n",
    "save_index = 0\n",
    "results_scraped = 0\n",
    "previous_page = 'https://www.yelp.com'\n",
    "breaker = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f41552ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|\u001b[38;2;10;144;146m█████████████████████████████████████████▉                                                                           \u001b[0m| 43/120 [02:59<05:21,  4.18s/profile]\u001b[0m\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m# index = main_df[main_df[\"Profile\"]== profile] \u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m scripts \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mxpath(\u001b[39m'\u001b[39;49m\u001b[39m//script[@type=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mapplication/json\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mtext\n\u001b[0;32m     35\u001b[0m head \u001b[39m=\u001b[39m scripts\u001b[39m.\u001b[39mindex(\u001b[39m'\u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m back \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(scripts)\u001b[39m-\u001b[39mscripts[\u001b[39mlen\u001b[39m(scripts)::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mindex(\u001b[39m'\u001b[39m\u001b[39m}\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for profile in tqdm(main_df[\"Profile\"][I:] ,unit= \"profile\", ncols = 160, colour= '#0A9092'):\n",
    "    \"\"\" scraping the internet\"\"\"  \n",
    "    ua = UserAgent()\n",
    "    \n",
    "    header = {\n",
    "                'user agent': ua,\n",
    "                'origin': 'https://www.yelp.com',\n",
    "                'referer':f'{previous_page}',\n",
    "                }\n",
    "    while True:\n",
    "        try:\n",
    "            try:\n",
    "                breaker = open(f'breaker.txt','r')\n",
    "                breaker = True\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            session = HTMLSession()\n",
    "            r = session.get(profile)\n",
    "            response = r.html\n",
    "            break       \n",
    "        except:\n",
    "            ua = UserAgent().random\n",
    "            sleep(5)\n",
    "            \n",
    "    if breaker == True:\n",
    "        break\n",
    "    \n",
    "    # index = main_df[main_df[\"Profile\"]== profile] \n",
    "        \n",
    "    scripts = response.xpath('//script[@type=\"application/json\"]')[1].text\n",
    "    head = scripts.index('{')\n",
    "    back = len(scripts)-scripts[len(scripts)::-1].index('}')\n",
    "    j_script =  scripts[head:back]                    \n",
    "    data = json.loads(j_script)\n",
    "        \n",
    "    review_found = False\n",
    "    ratting_found = False\n",
    "    for D in data:\n",
    "        if '.phoneNumber' in D: \n",
    "            try:\n",
    "                phone = data[D]['formatted']\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        if '.location.address' in D:    \n",
    "            try:    \n",
    "                address = data[D][\"formatted\"]\n",
    "            except:\n",
    "                pass    \n",
    "            \n",
    "        if '.externalResources.website' in D:    \n",
    "            try:    \n",
    "                website = 'https://www.'+ data[D]['url'].split(';')[-1]\n",
    "            except:\n",
    "                pass      \n",
    "                        \n",
    "        if ratting_found == False:    \n",
    "            try:    \n",
    "                ratting = int(data[D]['rating'])\n",
    "                ratting_found = True\n",
    "            except:\n",
    "                pass \n",
    "                \n",
    "        if review_found == False:    \n",
    "            try:    \n",
    "                review = int(data[D]['reviewCount'])\n",
    "                review_found = True\n",
    "            except:\n",
    "                pass \n",
    "        \n",
    "    B_contacts = {\"Phone\": phone, \"Address\": address, \"Website\": website, \"Rating\": ratting, \"Review Count\": review}\n",
    "    contacts.append(B_contacts)\n",
    "    \n",
    "    for key, value in B_contacts.items():\n",
    "        if value == '':\n",
    "            B_contacts[key] = \"Not Listed\"\n",
    "                    \n",
    "    contacts.append(B_contacts)\n",
    "    profile_no += 1\n",
    "    \n",
    "    if len(contacts) == 10: # saving the outputs to a csv file every 100 page\n",
    "        results_scraped += len(contacts)\n",
    "        save_index += 1\n",
    "        \n",
    "        s_df = pd.DataFrame(contacts)\n",
    "        s_df.to_csv(f\"Yelp {search_subject} in {search_location} {save_index} secondary.csv\", index= False)  \n",
    "        \n",
    "        contacts = []\n",
    "        \n",
    "        file = open(f'tracker {search_subject} in {search_location} at {date_time}.txt','a')\n",
    "        file.write('\\n')\n",
    "        file.write (f\"Yelp {search_subject} in {search_location} {save_index} secondary.csv\") \n",
    "        file.write('\\n')\n",
    "        file.write(F'{profile_no}')   \n",
    "        file.close()\n",
    "        \n",
    "    previous_page = profile\n",
    "    sleep(0.7) \n",
    "         \n",
    "s_df0 = pd.DataFrame(contacts)\n",
    "s_df0.to_csv(f\"Yelp {search_subject} in {search_location} 0 secondary.csv\", index= False)\n",
    "file = open(f'tracker {search_subject} in {search_location} at {date_time}.txt','a')\n",
    "file.write('\\n')\n",
    "file.write (f\"Yelp {search_subject} in {search_location} 0 secondary.csv\") \n",
    "file.write('\\n')   \n",
    "file.close()\n",
    "\n",
    "print(f\"Secondary is done, {results_scraped + len(result_list)} results Scraped successfully !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.yelp.com/biz/ekco-tax-services-san-francisco?osq=accountants'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f'tracker {search_subject} in {search_location} at {date_time}.txt','r')\n",
    "for line in file:\n",
    "    \n",
    "    if f'{search_location} 1 secondary' in line:\n",
    "        s_df0 = pd.read_csv(str(line).strip('\\n')) \n",
    "        continue \n",
    "     \n",
    "    if 'https://' not in line and 'secondary' in line: #and ' 0 secondary' not in line\n",
    "        s_df = pd.concat([s_df0, pd.read_csv(str(line).strip('\\n'))], axis=0, ignore_index= True)    \n",
    "        s_df0 = s_df\n",
    "        \n",
    "file.close()\n",
    "secondary_df = s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59bd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89695fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_df.to_csv(f\"Yelp Secondary {search_subject} in {search_location}.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    if 'Main' in file or 'Secondary' in file :\n",
    "        continue\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246beb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = main_df.join(secondary_df)\n",
    "df_combined.index += 1  # make the index start from one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784616b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(f\"Yelp {search_subject} in {search_location}.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    if 'Main' in file or 'Secondary' in file :\n",
    "        os.remove(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8823af32175d41bfca297386eea8c1e23370595e130acdcb57ee9569b0d429e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
